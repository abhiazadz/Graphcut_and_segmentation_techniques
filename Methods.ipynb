{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bacterial-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import cv2\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-polyester",
   "metadata": {},
   "source": [
    "## Graph-cut based segmentation using Pymaxflow\n",
    "Using energy minimization alogorithms such as aexpansion_grid and abswap_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hindu-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maxflow.fastmin import aexpansion_grid, abswap_grid, energy_of_grid_labeling\n",
    "\n",
    "def graph_cut(img,type_,level_start):\n",
    "\n",
    "    img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    d=25;s=55;\n",
    "    img = cv2.bilateralFilter(img, d, s, s)\n",
    "\n",
    "    I = img\n",
    "    I = I[:,:,1]/I.max()\n",
    "    #print(\"Img shape: \", img.shape)\n",
    "    #print(\"I shape: \", I.shape)\n",
    "\n",
    "    # Generates 16 gray levels for nearsest prototype labeling\n",
    "    L = 2\n",
    "    levs = np.arange(level_start/L, 1, 1/L) # 0.92 for 1 and 3\n",
    "    #print(levs)\n",
    "    #print(\"levs: \", levs)\n",
    "\n",
    "    # Calculate data cost as the absolute difference between the label prototype and the pixel value\n",
    "    D = np.abs(I.reshape(I.shape+(1,)) - levs.reshape((1,1,-1)))\n",
    "    #print(\"I.reshape(I.shape+(1,)): \", I.reshape(I.shape+(1,)))\n",
    "    #print(\"levs.reshape((1,1,-1): \",levs.reshape((1,1,-1)))\n",
    "    #print(\"I.reshape(I.shape+(1,)) - levs.reshape((1,1,-1)): \", I.reshape(I.shape+(1,)) - levs.reshape((1,1,-1)))\n",
    "    #print(\"D: \", D)\n",
    "    \n",
    "    # Generate nearest prototype labeling\n",
    "    Id = np.argmin(D,2)\n",
    "    #print(\"Id: \", Id)\n",
    "\n",
    "    # Calculate neighbourhood cost as absolute difference between prototypes \n",
    "    alpha = 1\n",
    "    V = alpha * np.abs( levs.reshape((-1,1)) - levs.reshape((1,-1)))\n",
    "    #print(\"V: \", V)\n",
    "    \n",
    "    # Mimimise data + neighbourhood cost\n",
    "    if type_== \"abswap_grid\":\n",
    "        labels_gc = abswap_grid(D,V,max_cycles=1000)\n",
    "    elif type_ == \"aexpansion_grid\":\n",
    "        labels_gc = aexpansion_grid(D,V,max_cycles=1000)\n",
    "\n",
    "    #energy_of_grid_labeling(D,V,labels=2)\n",
    "    # abswap_grid aexpansion_grid\n",
    "\n",
    "    '''\n",
    "    plt.figure(figsize = (20,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(Id, cmap = 'gray')\n",
    "    plt.title(label = 'Direct labeling')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(labels, cmap = 'gray')\n",
    "    plt.title(label = 'Regularised labeling')\n",
    "    plt.show\n",
    "    '''\n",
    "    #plt.imshow(labels5_gc, cmap = 'gray')\n",
    "    return labels_gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handled-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(img,Thres_blockSize, thres_switch):\n",
    "    \n",
    "    thres= img\n",
    "    ###Assigning values based on Trackerâ€™s position\n",
    "    thres_switch = cv2.getTrackbarPos('thres_switch','trackbar')\n",
    "    #Assign Kernel blocksize for Thresholding only if trackbar is active\n",
    "\n",
    "    Thres_blockSize = 1 + 2*cv2.getTrackbarPos('Thres_blockSize','trackbar')\n",
    "    #Assign Shift contstant value for Thresholding only if trackbar is active\n",
    "    if cv2.getTrackbarPos('c_sub','trackbar'):\n",
    "        c_sub = cv2.getTrackbarPos('c_sub','trackbar')\n",
    "    elif thres_switch == 1:\n",
    "        thres = cv2.adaptiveThreshold (img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, Thres_blockSize, c_sub)\n",
    "\n",
    "    #Binarizing  using Thresold_Otsu after a Gausian blur if thres_otsu variable is in ON position  \n",
    "    elif thres_switch == 2:\n",
    "        #thresh = threshold_otsu(image)\n",
    "        #binary = image > thresh\n",
    "        gaus = cv2.GaussianBlur(img,(3,3),0)\n",
    "        ret3,thres = cv2.threshold(gaus,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        \n",
    "    return thres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "challenging-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHist(img,showw):\n",
    "    hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * float(hist.max()) / cdf.max()\n",
    "    plt.plot(cdf_normalized, color = 'r')\n",
    "    plt.hist(img.flatten(),256,[0,256], color = 'g')\n",
    "    plt.xlim([0,256])\n",
    "    plt.legend(('cdf','histogram'), loc = 'lower right')\n",
    "    if showw == \"True\":\n",
    "        plt.show()\n",
    "    return plt\n",
    "\n",
    "\n",
    "def PSNR(image1, image2):\n",
    "\n",
    "    # OpenCV\n",
    "    #psnr =  cv2.PSNR(image1, image2)\n",
    "    #print('OpenCV PSNR: ',psnr)39\n",
    "\n",
    "    # Own implementation\n",
    "    mse = np.mean((image1.astype(np.float64) / 255 - image2.astype(np.float64) / 255) ** 2)\n",
    "    psnr = 10 * math.log10(1. / mse)\n",
    "    #print('Own implementation: ', 10 * math.log10(1. / mse))\n",
    "    return psnr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enormous-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_mat_seg(y_true, y_pred_t, setname):\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : Ground truth mask \n",
    "    y_pred_t : Predicted mask\n",
    "    setname : Name description for the confusion matrix\n",
    "    mydir : Outout directory to save the cm image\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    tp = np.logical_and(y_true==True, y_pred_t==True)\n",
    "    tn = np.logical_and(y_true==False, y_pred_t==False)\n",
    "    fp = np.logical_and(y_true==True, y_pred_t==False)\n",
    "    fn = np.logical_and(y_true==False, y_pred_t==True)\n",
    "    \n",
    "    cmat = [[np.sum(tp), np.sum(fn)], [np.sum(fp), np.sum(tn)]]\n",
    "\n",
    "\n",
    "    plt.figure(figsize = (6,6))\n",
    "    plt.title(setname)\n",
    "    sns.heatmap(cmat/np.sum(cmat), cmap=\"Reds\", annot=True, fmt = '.2%', square=1, linewidth=2.)\n",
    "    plt.xlabel(\"predictions\")\n",
    "    plt.ylabel(\"real values\")\n",
    "    #plt.savefig(mydir + setname + 'confusion_mat_seg.png')\n",
    "    try:\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    iou = np.sum(tp)/(np.sum(tp)+np.sum(fn)+np.sum(fp))\n",
    "    f1 = (2*np.sum(tp))/((2*np.sum(tp))+np.sum(fn)+np.sum(fp))\n",
    "    precision =  np.sum(tp)/(np.sum(tp)+np.sum(fp)) #pixcel_accuracy\n",
    "    \n",
    "    acc = (np.sum(tp)+np.sum(tn))/(np.sum(tp)+np.sum(tn)+np.sum(fn)+np.sum(fp))\n",
    "    sensitivity= np.sum(tp)/(np.sum(tp)+np.sum(fn)) \n",
    "    specificity = np.sum(tn)/(np.sum(tn)+np.sum(fp)) \n",
    "    \n",
    "    print('IoU score: ',iou,'\\nF1 score:', f1,'\\nPrecision:', precision,'\\nSensitivity:', sensitivity,'\\nSpecificity:', specificity,'\\nAccuracy:', acc)\n",
    "    return([iou, f1, precision, sensitivity, specificity, acc])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
